{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "555c094b",
   "metadata": {},
   "source": [
    "This notebook merges the original Training and Testing MRI folders, resizes all images to 224 x 224, and prepares a clean directory structure for later splitting and augmentation.\n",
    "\n",
    "It follows the preprocessing methodology described in the LEAD-CNN paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this notebook we perform the following preprocessing steps:\n",
    "\n",
    "\n",
    "1. Merge the original Training and Testing datasets\n",
    "2. Resize all images to 224 × 224\n",
    "3. Prepare the cleaned dataset directory structure for later splitting and augmentation\n",
    "\n",
    "\n",
    "These steps replicate the image standardization stage described in the LEAD‑CNN paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f245c4",
   "metadata": {},
   "source": [
    "We merge both the Training and Testing folders from the original dataset and resize all images before performing any splitting.\n",
    "\n",
    "\n",
    "This ensures:\n",
    "- Randomized distribution in later steps\n",
    "- Uniform input size for CNN models\n",
    "- Consistency with the methodology of the research paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41017c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MRI DATASET CLEANING AND MERGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b9c244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version: 4.12.0\n",
      "NumPy version: 2.2.6\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "print(\"NumPy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbcce2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Utilities\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca48fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths (Windows friendly)\n",
    "RAW_TRAIN_DIR = Path(r\"..\\\\data\\\\raw_data\\\\Training\")\n",
    "RAW_TEST_DIR = Path(r\"..\\\\data\\\\raw_data\\\\Testing\")\n",
    "CLEAN_DIR = Path(r\"..\\\\data\\\\cleaned_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90f87bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
      "Target image size: (224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Configuring Dataset for the inner folders and defining the image size to resize to\n",
    "CLASSES = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "\n",
    "print(\"Classes:\", CLASSES)\n",
    "print(\"Target image size:\", IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82697a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder structure created under: C:\\Users\\ekowd\\Desktop\\FYP\\FYP\\data\\cleaned_data\n"
     ]
    }
   ],
   "source": [
    "# Defining The Folder Structure for the Cleaned Dataset\n",
    "for split in ['train', 'val', 'test']:\n",
    "  for cls in CLASSES:\n",
    "    path = CLEAN_DIR / split / cls\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "print(\"Folder structure created under:\", CLEAN_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eb14329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\ekowd\\Desktop\\FYP\\FYP\\notebooks\n",
      "RAW_TRAIN_DIR exists: True -> C:\\Users\\ekowd\\Desktop\\FYP\\FYP\\data\\raw_data\\Training\n",
      "RAW_TEST_DIR exists: True -> C:\\Users\\ekowd\\Desktop\\FYP\\FYP\\data\\raw_data\\Testing\n",
      "CLEAN_DIR exists: True -> C:\\Users\\ekowd\\Desktop\\FYP\\FYP\\data\\cleaned_data\n",
      "..\\data\\raw_data\\Training\\glioma: 1321 files\n",
      " Sample image shape: (512, 512, 3)\n",
      "..\\data\\raw_data\\Testing\\glioma: 300 files\n",
      " Sample image shape: (512, 512, 3)\n",
      "..\\data\\raw_data\\Training\\meningioma: 1339 files\n",
      " Sample image shape: (512, 512, 3)\n",
      "..\\data\\raw_data\\Testing\\meningioma: 306 files\n",
      " Sample image shape: (278, 440, 3)\n",
      "..\\data\\raw_data\\Training\\notumor: 1595 files\n",
      " Sample image shape: (350, 350, 3)\n",
      "..\\data\\raw_data\\Testing\\notumor: 405 files\n",
      " Sample image shape: (236, 236, 3)\n",
      "..\\data\\raw_data\\Training\\pituitary: 1457 files\n",
      " Sample image shape: (512, 512, 3)\n",
      "..\\data\\raw_data\\Testing\\pituitary: 300 files\n",
      " Sample image shape: (512, 512, 3)\n",
      "If any folder has 0 files, ensure the dataset/file path is placed correctly.\n"
     ]
    }
   ],
   "source": [
    "# Dataset Check to ensure folders are created correctly\n",
    "\n",
    "print(\"Current working directory:\", Path.cwd())\n",
    "print(\"RAW_TRAIN_DIR exists:\", RAW_TRAIN_DIR.exists(), \"->\", RAW_TRAIN_DIR.resolve())\n",
    "print(\"RAW_TEST_DIR exists:\", RAW_TEST_DIR.exists(), \"->\", RAW_TEST_DIR.resolve())\n",
    "print(\"CLEAN_DIR exists:\", CLEAN_DIR.exists(), \"->\", CLEAN_DIR.resolve())\n",
    "\n",
    "\n",
    "for cls in CLASSES:\n",
    "  for data_dir in [RAW_TRAIN_DIR, RAW_TEST_DIR]:\n",
    "    class_dir = data_dir / cls\n",
    "    if class_dir.exists():\n",
    "      files = list(class_dir.glob('*'))\n",
    "      print(f\"{class_dir}: {len(files)} files\")\n",
    "      if files:\n",
    "        img = cv2.imread(str(files[0]))\n",
    "        print(f\" Sample image shape: {img.shape if img is not None else 'Failed to load'}\")\n",
    "    else:\n",
    "      print(f\"{class_dir}: does not exist\")\n",
    "\n",
    "\n",
    "print(\"If any folder has 0 files, ensure the dataset/file path is placed correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ec11c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and Rezising Images (function)\n",
    "def load_and_resize_images(class_name):\n",
    "  \"\"\"\n",
    "  Loads images from both raw Training and Testing directories,\n",
    "  resizes them to IMG_SIZE, and returns a list of (image_array, filename).\n",
    "  \"\"\"\n",
    "  images = []\n",
    "\n",
    "\n",
    "  for data_dir in [RAW_TRAIN_DIR, RAW_TEST_DIR]:\n",
    "    class_dir = data_dir / class_name\n",
    "    if not class_dir.exists():\n",
    "      continue\n",
    "    \n",
    "    for file_path in class_dir.glob('*'):\n",
    "      if file_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "        img = cv2.imread(str(file_path))\n",
    "        if img is None:\n",
    "          continue\n",
    "        resized = cv2.resize(img, IMG_SIZE)\n",
    "        images.append((resized, file_path.name))\n",
    "  \n",
    "  return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b87072c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Images to Cleaned Directory (function)\n",
    "\n",
    "def save_images(images, save_dir, class_name):\n",
    "  \"\"\"\n",
    "  Saves a list of (image_array, filename) into save_dir/class_name\n",
    "  \"\"\"\n",
    "  for img_array, filename in images:\n",
    "    save_path = save_dir / class_name / filename\n",
    "    cv2.imwrite(str(save_path), img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b2c12dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing class: glioma\n",
      "Total merged images: 1621\n",
      "Saving resized images to cleaned_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: glioma -> 1621 images saved\n",
      "\n",
      "Processing class: meningioma\n",
      "Total merged images: 1645\n",
      "Saving resized images to cleaned_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: meningioma -> 1645 images saved\n",
      "\n",
      "Processing class: notumor\n",
      "Total merged images: 2000\n",
      "Saving resized images to cleaned_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: notumor -> 2000 images saved\n",
      "\n",
      "Processing class: pituitary\n",
      "Total merged images: 1757\n",
      "Saving resized images to cleaned_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: pituitary -> 1757 images saved\n",
      "\n",
      "Dataset merging and resizing completed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Merge and Resize All Classes\n",
    "# The performs the actually dataset merging and resizing\n",
    "\n",
    "for cls in CLASSES:\n",
    "  print(f\"\\nProcessing class: {cls}\")\n",
    "\n",
    "  images = load_and_resize_images(cls)\n",
    "  total_images = len(images)\n",
    "\n",
    "  print(f\"Total merged images: {total_images}\")\n",
    "\n",
    "  if total_images == 0:\n",
    "    print(f\"Skipping {cls} – no images found.\")\n",
    "    continue\n",
    "\n",
    "  print(\"Saving resized images to cleaned_data...\")\n",
    "  save_images(tqdm(images, leave=False), CLEAN_DIR / 'train', cls)\n",
    "\n",
    "  print(f\"Done: {cls} -> {total_images} images saved\")\n",
    "\n",
    "print(\"\\nDataset merging and resizing completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab35c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
