{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2383ec2",
   "metadata": {},
   "source": [
    "This notebook takes the resized images produced in 01_data_merge_and_cleaning.ipynb and performs:\n",
    "\n",
    "Deterministic shuffling\n",
    "\n",
    "Train / Validation / Test splitting (80% / 10% / 10%)\n",
    "\n",
    "Class‑balanced distribution\n",
    "\n",
    "Dataset statistics export\n",
    "\n",
    "It follows the dataset distribution methodology described in the LEAD‑CNN paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798a66f9",
   "metadata": {},
   "source": [
    "In this notebook we:\n",
    "\n",
    "\n",
    "1. Load the cleaned dataset produced in Notebook 01\n",
    "2. Randomly shuffle images per class (deterministic)\n",
    "3. Split data into training, validation, and test sets (80/10/10)\n",
    "4. Save files into their respective folders\n",
    "5. Generate dataset statistics for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fc5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MRI Dataset Splitting (Train / Validation / Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508289ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0266c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "CLEAN_DIR = Path(r\"..\\\\data\\\\cleaned_data\")\n",
    "STATS_DIR = Path(r\"..\\\\data\\\\dataset_stats\")\n",
    "STATS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Configuration\n",
    "CLASSES = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "SPLIT_RATIOS = {\n",
    "'train': 0.8,\n",
    "'val': 0.1,\n",
    "'test': 0.1\n",
    "}\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2976181",
   "metadata": {},
   "source": [
    "Manual Check\n",
    "\n",
    "Before proceeding, ensure the following directory exists and contains images:\n",
    "\n",
    "`cleaned_data/train/<class_name>/*.jpg`\n",
    "\n",
    "The validation and test folders should currently be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1318c0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glioma: 1621 images in cleaned train folder\n",
      "meningioma: 1645 images in cleaned train folder\n",
      "notumor: 2000 images in cleaned train folder\n",
      "pituitary: 1757 images in cleaned train folder\n"
     ]
    }
   ],
   "source": [
    "for cls in CLASSES:\n",
    "  train_dir = CLEAN_DIR / 'train' / cls\n",
    "  files = list(train_dir.glob('*'))\n",
    "  print(f\"{cls}: {len(files)} images in cleaned train folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a989b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_directory(directory: Path):\n",
    "  \"\"\"Remove all files from a directory.\"\"\"\n",
    "  for f in directory.glob('*'):\n",
    "    if f.is_file():\n",
    "      f.unlink()\n",
    "\n",
    "\n",
    "def split_list(items, train_ratio, val_ratio, test_ratio):\n",
    "  \"\"\"Split list into train/val/test using provided ratios.\"\"\"\n",
    "  n = len(items)\n",
    "\n",
    "\n",
    "  n_train = int(n * train_ratio)\n",
    "  n_val = int(n * val_ratio)\n",
    "\n",
    "\n",
    "  train_items = items[:n_train]\n",
    "  val_items = items[n_train:n_train + n_val]\n",
    "  test_items = items[n_train + n_val:]\n",
    "\n",
    "\n",
    "  return train_items, val_items, test_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7d980b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation and test folders cleared.\n"
     ]
    }
   ],
   "source": [
    "# On Hind Sight, Better to Clear Existing Validation and Test Folders\n",
    "\n",
    "for split in ['val', 'test']:\n",
    "  for cls in CLASSES:\n",
    "    clear_directory(CLEAN_DIR / split / cls)\n",
    "\n",
    "\n",
    "print(\"Validation and test folders cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da01a940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing class: glioma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glioma → Train: 1296, Val: 162, Test: 163\n",
      "\n",
      "Processing class: meningioma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meningioma → Train: 1316, Val: 164, Test: 165\n",
      "\n",
      "Processing class: notumor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notumor → Train: 1600, Val: 200, Test: 200\n",
      "\n",
      "Processing class: pituitary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pituitary → Train: 1405, Val: 175, Test: 177\n",
      "\n",
      "Dataset splitting completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Statistics On teh Dataset Splitting Would Be Useful for Analysis Later\n",
    "\n",
    "dataset_stats = []\n",
    "\n",
    "\n",
    "for cls in CLASSES:\n",
    "  print(f\"\\nProcessing class: {cls}\")\n",
    "\n",
    "\n",
    "  class_train_dir = CLEAN_DIR / 'train' / cls\n",
    "  images = list(class_train_dir.glob('*'))\n",
    "\n",
    "\n",
    "  if len(images) == 0:\n",
    "    print(f\"No images found for {cls}, skipping.\")\n",
    "    continue\n",
    "\n",
    "\n",
    "  # Shuffle deterministically\n",
    "  random.shuffle(images)\n",
    "\n",
    "\n",
    "  # Split\n",
    "  train_imgs, val_imgs, test_imgs = split_list(\n",
    "    images,\n",
    "    SPLIT_RATIOS['train'],\n",
    "    SPLIT_RATIOS['val'],\n",
    "    SPLIT_RATIOS['test']\n",
    "    )\n",
    "\n",
    "\n",
    "  # Move validation images\n",
    "  for img_path in tqdm(val_imgs, desc=f\"{cls} → val\", leave=False):\n",
    "    shutil.move(str(img_path), str(CLEAN_DIR / 'val' / cls / img_path.name))\n",
    "\n",
    "\n",
    "  # Move test images\n",
    "  for img_path in tqdm(test_imgs, desc=f\"{cls} → test\", leave=False):\n",
    "    shutil.move(str(img_path), str(CLEAN_DIR / 'test' / cls / img_path.name))\n",
    "\n",
    "\n",
    "  dataset_stats.append({\n",
    "    'class': cls,\n",
    "    'train': len(train_imgs),\n",
    "    'val': len(val_imgs),\n",
    "    'test': len(test_imgs),\n",
    "    'total': len(images)\n",
    "  })\n",
    "\n",
    "\n",
    "  print(f\"{cls} → Train: {len(train_imgs)}, Val: {len(val_imgs)}, Test: {len(test_imgs)}\")\n",
    "\n",
    "\n",
    "print(\"\\nDataset splitting completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2f42265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            class  train  val  test  total\n",
       " 0          glioma   1296  162   163   1621\n",
       " 1      meningioma   1316  164   165   1645\n",
       " 2         notumor   1600  200   200   2000\n",
       " 3       pituitary   1405  175   177   1757\n",
       " Total       TOTAL   5617  701   705   7023,\n",
       " WindowsPath('../data/dataset_stats/split_summary.csv'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving Dataset Statistics\n",
    "\n",
    "stats_df = pd.DataFrame(dataset_stats)\n",
    "stats_df.loc['Total'] = ['TOTAL', stats_df.train.sum(), stats_df.val.sum(), stats_df.test.sum(), stats_df.total.sum()]\n",
    "\n",
    "\n",
    "stats_path = STATS_DIR / 'split_summary.csv'\n",
    "stats_df.to_csv(stats_path, index=False)\n",
    "\n",
    "\n",
    "stats_df, stats_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c73a94bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN set:\n",
      " glioma: 1296\n",
      " meningioma: 1316\n",
      " notumor: 1600\n",
      " pituitary: 1405\n",
      "\n",
      "VAL set:\n",
      " glioma: 162\n",
      " meningioma: 164\n",
      " notumor: 200\n",
      " pituitary: 175\n",
      "\n",
      "TEST set:\n",
      " glioma: 163\n",
      " meningioma: 165\n",
      " notumor: 200\n",
      " pituitary: 177\n"
     ]
    }
   ],
   "source": [
    "# Double Checking the Number of Images in Each Split After Moving\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "  print(f\"\\n{split.upper()} set:\")\n",
    "  for cls in CLASSES:\n",
    "    count = len(list((CLEAN_DIR / split / cls).glob('*')))\n",
    "    print(f\" {cls}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd71ca3",
   "metadata": {},
   "source": [
    "After executing all the code, desired output would be\n",
    "``\n",
    "cleaned_data/\n",
    "  train/<class>/\n",
    "  val/<class>/\n",
    "  test/<class>/``\n",
    "\n",
    "And you will/should also have a dataset Statistic File\n",
    "`data/dataset_stats/split_summary.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb622e5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
